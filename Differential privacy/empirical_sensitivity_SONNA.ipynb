{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import statments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Empirical Sensitivity.\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from utils import get_data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import logsumexp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_hist(array_of_empirical_sensitivities, n, lmbda, name):\n",
    "    if not isinstance(array_of_empirical_sensitivities, np.ndarray):\n",
    "        raise ValueError('array_of_empirical_sensitivities should be a np.ndarray.')\n",
    "    if not isinstance(name, str):\n",
    "        raise ValueError('name should be a str')\n",
    "\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    ################################################################\n",
    "    # TODO(student): replace below with correct theoretical max sensitivity\n",
    "    max_theoretical_sensitivity = 2/(n * lmbda)\n",
    "    ################################################################\n",
    "\n",
    "    num_bins = 20\n",
    "    dirname = './figs'\n",
    "    filename = os.path.join(dirname, name) + '.histogram.png'\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xscale('log')\n",
    "    bin_values, _, _ = ax.hist(array_of_empirical_sensitivities, \n",
    "            num_bins, label='empirical sensitivities')\n",
    "    ax.set_title('histogram of sensitivities: ' + name)\n",
    "    ax.axvline(x=max_theoretical_sensitivity, color='r', linestyle='dashed', linewidth=2,\n",
    "            label='theoretical max sensitivity')\n",
    "    ax.legend()\n",
    "    fig.savefig(filename)\n",
    "    return filename\n",
    "\n",
    "\n",
    "def plot_extreme_neighbors(sensitivities, list_of_neighboring_examples, name):\n",
    "    \"\"\"Plots to disk the neighboring-example pairs with the most and least empirical sensitivity\n",
    "    \n",
    "    Note on the data structures used: \n",
    "        sensitivities: a np.ndarray containing empirical sensitivities for each run\n",
    "        list_of_neighboring_examples: a list of neighboring example pairs, one for each run. in other words:\n",
    "        \n",
    "        list_of_neighboring_examples = [\n",
    "            neighboring_example_1, \n",
    "            neighboring_example_2,  \n",
    "            ...\n",
    "            neighboring_example_n,\n",
    "            ]\n",
    "            \n",
    "        where each tuple in the list represents the data diff between the neighboring \n",
    "        datasets and is formatted like this:\n",
    "        \n",
    "        neighboring_example_i = (\n",
    "            (neighbor_img_i, neighbor_label_i),\n",
    "            (neighbor_img_i_prime, neighbor_label_i_prime),\n",
    "        )\n",
    "        \n",
    "        See utils.py if you are still confused.\n",
    "    \"\"\"\n",
    "    if not isinstance(sensitivities, np.ndarray):\n",
    "        raise ValueError('sensitivies should be a np.ndarray.')\n",
    "    first_neighbor_pair = list_of_neighboring_examples[0]\n",
    "    if not isinstance(list_of_neighboring_examples, list) or not isinstance(first_neighbor_pair, tuple) \\\n",
    "            or not isinstance(first_neighbor_pair[0][0], torch.Tensor):\n",
    "        raise ValueError('list_of_neighboring_examples should be a list of tuple pairs, where tuple contains img tensors')\n",
    "    if not isinstance(name, str):\n",
    "        raise ValueError('name should be a str')\n",
    "\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "\n",
    "\n",
    "    ############################################################################\n",
    "    # TODO(student)\n",
    "    #\n",
    "    # using list_of_empirical_sensitivies and neighboring_examples, create two image plots\n",
    "    # 1) side-by-side images for neighbor-pair that maximizes sensitivity\n",
    "    # 2) side-by-side images for neighbor-pair that minimizes sensitivity\n",
    "    #\n",
    "    # matplotlib.subplots and matplotlib.imshow may come in handy\n",
    "    dirname = './figs'\n",
    "\n",
    "    filename1 = os.path.join(dirname, name) + '.minimum.png'\n",
    "    filename2 = os.path.join(dirname, name) + '.maximum.png'\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "        \n",
    "    minimum= np.argmin(sensitivities)\n",
    "    maximum= np.argmax(sensitivities)\n",
    "    \n",
    "   \n",
    "    item_min= list_of_neighboring_examples[minimum]\n",
    "    item_max= list_of_neighboring_examples[maximum]\n",
    "    \n",
    "    item_min_neighbor, item_min_neighbor_prime= item_min\n",
    "    item_max_neighbor, item_max_neighbor_prime= item_max\n",
    "    \n",
    "    \n",
    "    item_min_neighbor_img, item_min_neighbor_label= item_min_neighbor\n",
    "    item_min_neighbor_prime_img, item_min_neighbor_prime_label= item_min_neighbor_prime\n",
    "    \n",
    "    item_max_neighbor_img, item_max_neighbor_label= item_max_neighbor\n",
    "    item_max_neighbor_prime_img, item_max_neighbor_prime_label= item_max_neighbor_prime\n",
    "    \n",
    "     \n",
    "    fig1, ax1s = plt.subplots(1, 2)\n",
    "    fig2, ax2s = plt.subplots(1, 2)\n",
    "    \n",
    "    pil_transform= transforms.ToPILImage()\n",
    "        \n",
    "    ax1s[0].imshow(pil_transform(item_min_neighbor_img))\n",
    "    ax1s[1].imshow(pil_transform(item_min_neighbor_prime_img))\n",
    "        \n",
    "    ax2s[0].imshow(pil_transform(item_max_neighbor_img))\n",
    "    ax2s[1].imshow(pil_transform(item_max_neighbor_prime_img))\n",
    "        \n",
    "    fig1.savefig(filename1)\n",
    "    fig2.savefig(filename2)\n",
    "    #\n",
    "    filenames = filename1, filename2\n",
    "    #raise NotImplementedError\n",
    "    ############################################################################\n",
    "\n",
    "    return filenames\n",
    "\n",
    "\n",
    "def compute_empricial_sensivity(train_loader, neighbor_loader,\n",
    "        num_epochs, learning_rate, lmbda, model_seed=None):\n",
    "    ############################################################################\n",
    "    # TODO(student)\n",
    "    #\n",
    "    # your code here...\n",
    "    from logistic_regression import nonprivate_logistic_regression\n",
    "    \n",
    "    model_train= nonprivate_logistic_regression(train_loader, num_epochs, learning_rate,lmbda, model_seed)\n",
    "    model_neighbor= nonprivate_logistic_regression(neighbor_loader, num_epochs, learning_rate,lmbda, model_seed)\n",
    "    \n",
    "    weight_train= model_train['weight']\n",
    "    weight_neighbor= model_neighbor['weight']\n",
    "    \n",
    "    sensitivity= torch.norm((weight_train - weight_neighbor),p=2)\n",
    "    \n",
    "    ############################################################################\n",
    "    return sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(n, runs, epochs, lr, batch_size, model_seed, lmbda):\n",
    "    list_of_empirical_sensitivies = []\n",
    "    list_of_neighboring_examples = []\n",
    "    for data_seed in range(runs):\n",
    "        loaders, neighboring_examples = get_data_loaders(data_seed, batch_size, \n",
    "                num_train=n)\n",
    "        sensitivity = compute_empricial_sensivity(\n",
    "                loaders['train'], loaders['neighbor'],\n",
    "                epochs, lr, lmbda, model_seed)\n",
    "        list_of_empirical_sensitivies.append(sensitivity)\n",
    "        list_of_neighboring_examples.append(neighboring_examples)\n",
    "\n",
    "    list_of_empirical_sensitivies = np.array(list_of_empirical_sensitivies)\n",
    "    sensitivity_upper_bound = 3.\n",
    "    name = 'lambda={},n={}'.format(lmbda, n)\n",
    "    filename = plot_hist(list_of_empirical_sensitivies, n, lmbda, name)\n",
    "    print('see plot at', filename)\n",
    "\n",
    "    filenames = plot_extreme_neighbors(list_of_empirical_sensitivies, list_of_neighboring_examples, name)\n",
    "    print('see plots at {} and {}'.format(*filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arguments and main function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.92it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  8.89it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  9.70it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00, 10.21it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.82it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.88it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.67it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "see plot at ./figs/lambda=0.0005,n=1000.histogram.png\n",
      "see plots at ./figs/lambda=0.0005,n=1000.minimum.png and ./figs/lambda=0.0005,n=1000.maximum.png\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "RUNS = 4  # TODO(student): run more times once your code works; something like 100\n",
    "EPOCHS = 100\n",
    "LR = 0.1\n",
    "BATCH_SIZE = 256\n",
    "MODEL_SEED = 0\n",
    "LMBDA = 5e-4\n",
    "\n",
    "main(N, RUNS, EPOCHS, LR, BATCH_SIZE, MODEL_SEED, LMBDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- what score should we use to compare the models\n",
    "\n",
    "We have the choice between the Accuracy and the loss function: (1- loss function)\n",
    "\n",
    "the Accuracy just give us the percentage of samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
