{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Private Training by Output Perturbation.\"\"\"\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import ortho_group\n",
    "import torch\n",
    "from torch.distributions.gamma import Gamma\n",
    "from torch import nn\n",
    "\n",
    "from logistic_regression import nonprivate_logistic_regression\n",
    "from utils import get_data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pip3 install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gamma_sample_pytorch_parameterization(concentration, rate):\n",
    "    \"\"\"The Gamma dist'n as it is parameterized in PyTorch\"\"\"\n",
    "    return Gamma(concentration, rate).sample()\n",
    "\n",
    "\n",
    "def gamma_sample_chaudhuri_parameterization(concentration, scale):\n",
    "    \"\"\"The Gamma dist'n as it is parameterized in Chaudhuri and Monteleoni\"\"\"\n",
    "    rate = 1. / scale\n",
    "    return gamma_sample_pytorch_parameterization(concentration, rate)\n",
    "\n",
    "\n",
    "def random_unit_norm_vector(num_dims):\n",
    "    random_rotation_matrix = ortho_group.rvs(num_dims)\n",
    "    basis_vector_one = np.eye(num_dims)[0]\n",
    "    vector = np.matmul(random_rotation_matrix, basis_vector_one)\n",
    "    return torch.tensor(vector, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def private_logistic_regression(dset_loader, num_epochs, learning_rate,\n",
    "    lmbda, epsilon, seed=None):\n",
    "    ############################################################################\n",
    "    # TODO(student)\n",
    "    #\n",
    "    # your code here...\n",
    "    #\n",
    "    # hint: use the code we have given you. For example you don't have to \n",
    "    # implement non-private logistic regression from scratch because an \n",
    "    # implementation exists in logistic_regression.py. There are also functions \n",
    "    # in this file for sampling Laplace noise\n",
    "    #\n",
    "    # hint: the input dim d can be found as a attr of the dset_loader's dset\n",
    "    #       >>> num_pixels = dset_loader.dataset.num_pixels\n",
    "    #\n",
    "    pixels = dset_loader.dataset.num_pixels\n",
    "    \n",
    "    n = len(dset_loader.dataset)\n",
    "    \n",
    "    scale = 2/(n * epsilon * lmbda)\n",
    "    \n",
    "    noise  = random_unit_norm_vector(pixels)\n",
    "    \n",
    "    noise_norm = gamma_sample_chaudhuri_parameterization(pixels, scale)\n",
    "    \n",
    "    noise_Pertubation =  noise  * noise_norm\n",
    "        \n",
    "    nonprivate_params = nonprivate_logistic_regression(dset_loader, num_epochs, learning_rate, lmbda, seed)\n",
    "    \n",
    "    private_weight = nonprivate_params['weight'] + noise_Pertubation\n",
    "    \n",
    "    private_params = {\n",
    "        'weight': private_weight,  # replace me (but this is how to format the state_dict)\n",
    "        }\n",
    "    \n",
    "\n",
    "    \n",
    "    return private_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(n, epsilon, lmbda, epochs, batch_size, lr, data_seed, model_seed):\n",
    "    # load data\n",
    "    loaders, _ = get_data_loaders(data_seed, batch_size, n)\n",
    "    loaders.pop('neighbor')  # don't need this loader for this question\n",
    "  \n",
    "    # train model\n",
    "    nonprivate_params = \\\n",
    "            nonprivate_logistic_regression(loaders['train'], epochs, \n",
    "                    lr, lmbda, seed=model_seed)\n",
    "  \n",
    "    private_params = private_logistic_regression(loaders['train'], epochs, \n",
    "        lr, lmbda, epsilon, seed=model_seed)\n",
    "  \n",
    "    # evaluate\n",
    "    test_losses = dict()\n",
    "    test_accs = dict()\n",
    "    for name, params in zip(['nonprivate', 'private'], \n",
    "          [nonprivate_params, private_params]):\n",
    "        num_pixels = loaders['train'].dataset.num_pixels\n",
    "        model = nn.Linear(num_pixels, 1, bias=False)\n",
    "        criterion = nn.BCEWithLogitsLoss()  # binary cross entropy\n",
    "        model.load_state_dict(params)\n",
    "        model.eval()\n",
    "        num_test_examples = len(loaders['test'].dataset)\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0.\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in loaders['test']:\n",
    "                images = images.reshape(-1, 28*28)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs.squeeze(), labels.float())\n",
    "                test_loss += loss.item() * len(images) / float(num_test_examples)\n",
    "                predicted = (outputs.squeeze() > 0.).long()\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            test_acc = float(correct) / float(total)\n",
    "            test_losses[name] = test_loss\n",
    "            test_accs[name] = 100. * test_acc  # format as a percentage\n",
    "  \n",
    "    from pprint import pprint\n",
    "    print('final test losses')\n",
    "    print('nonprivate: {nonprivate:.2f}, private: {private:.2f}'\n",
    "          .format(**test_losses))\n",
    "    print('final test accs')\n",
    "    print('nonprivate: {nonprivate:.2f}, private: {private:.2f}'\n",
    "          .format(**test_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arguments and main function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:07<00:00,  7.64it/s]\n",
      "100%|██████████| 1000/1000 [02:11<00:00,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final test losses\n",
      "nonprivate: 0.24, private: 0.26\n",
      "final test accs\n",
      "nonprivate: 97.00, private: 94.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "EPSILON = 5.\n",
    "LMBDA = 1e-2\n",
    "EPOCHS = 1000  # run for more epochs once your code works\n",
    "BATCH_SIZE = 256\n",
    "LR = .1\n",
    "DATA_SEED = 0\n",
    "MODEL_SEED = 0\n",
    "main(N, EPSILON, LMBDA, EPOCHS, BATCH_SIZE, LR, DATA_SEED, MODEL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:56<00:00,  8.73it/s]\n",
      "100%|██████████| 1000/1000 [02:08<00:00,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final test losses\n",
      "nonprivate: 0.24, private: 0.21\n",
      "final test accs\n",
      "nonprivate: 97.00, private: 97.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "EPSILON = 5.\n",
    "LMBDA = 1e-2\n",
    "EPOCHS = 1000  # run for more epochs once your code works\n",
    "BATCH_SIZE = 256\n",
    "LR = .01\n",
    "DATA_SEED = 0\n",
    "MODEL_SEED = 0\n",
    "main(N, EPSILON, LMBDA, EPOCHS, BATCH_SIZE, LR, DATA_SEED, MODEL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:57<00:00,  7.86it/s]\n",
      "100%|██████████| 1000/1000 [02:02<00:00,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final test losses\n",
      "nonprivate: 0.24, private: 0.20\n",
      "final test accs\n",
      "nonprivate: 97.00, private: 96.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "EPSILON = 5.\n",
    "LMBDA = 1e-2\n",
    "EPOCHS = 1000  # run for more epochs once your code works\n",
    "BATCH_SIZE = 256\n",
    "LR = .05\n",
    "DATA_SEED = 0\n",
    "MODEL_SEED = 0\n",
    "main(N, EPSILON, LMBDA, EPOCHS, BATCH_SIZE, LR, DATA_SEED, MODEL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:00<00:10,  9.15it/s]\u001b[A\n",
      "  2%|▏         | 2/100 [00:00<00:10,  9.36it/s]\u001b[A\n",
      "  3%|▎         | 3/100 [00:00<00:10,  9.38it/s]\u001b[A\n",
      "  4%|▍         | 4/100 [00:00<00:10,  9.51it/s]\u001b[A\n",
      "  5%|▌         | 5/100 [00:00<00:10,  9.36it/s]\u001b[A\n",
      "  6%|▌         | 6/100 [00:00<00:09,  9.48it/s]\u001b[A\n",
      "  7%|▋         | 7/100 [00:00<00:09,  9.61it/s]\u001b[A\n",
      "  8%|▊         | 8/100 [00:00<00:09,  9.66it/s]\u001b[A\n",
      "  9%|▉         | 9/100 [00:00<00:09,  9.68it/s]\u001b[A\n",
      " 10%|█         | 10/100 [00:01<00:09,  9.70it/s]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:01<00:08,  9.85it/s]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:01<00:08,  9.96it/s]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:01<00:08,  9.92it/s]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:01<00:08, 10.01it/s]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:01<00:08,  9.95it/s]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:01<00:08,  9.88it/s]\u001b[A\n",
      " 20%|██        | 20/100 [00:02<00:08,  9.87it/s]\u001b[A\n",
      " 21%|██        | 21/100 [00:02<00:08,  9.67it/s]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:02<00:08,  9.54it/s]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:02<00:07,  9.63it/s]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:02<00:07,  9.57it/s]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:02<00:08,  9.28it/s]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:02<00:08,  9.20it/s]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:02<00:07,  9.52it/s]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:02<00:07,  9.51it/s]\u001b[A\n",
      " 30%|███       | 30/100 [00:03<00:07,  9.56it/s]\u001b[A\n",
      " 31%|███       | 31/100 [00:03<00:07,  9.66it/s]\u001b[A\n",
      " 32%|███▏      | 32/100 [00:03<00:07,  9.71it/s]\u001b[A\n",
      " 33%|███▎      | 33/100 [00:03<00:06,  9.78it/s]\u001b[A\n",
      " 34%|███▍      | 34/100 [00:03<00:06,  9.61it/s]\u001b[A\n",
      " 35%|███▌      | 35/100 [00:03<00:06,  9.68it/s]\u001b[A\n",
      " 36%|███▌      | 36/100 [00:03<00:06,  9.66it/s]\u001b[A\n",
      " 37%|███▋      | 37/100 [00:03<00:06,  9.67it/s]\u001b[A\n",
      " 39%|███▉      | 39/100 [00:04<00:06,  9.82it/s]\u001b[A\n",
      " 41%|████      | 41/100 [00:04<00:05,  9.94it/s]\u001b[A\n",
      " 43%|████▎     | 43/100 [00:04<00:05, 10.15it/s]\u001b[A\n",
      " 45%|████▌     | 45/100 [00:04<00:05, 10.09it/s]\u001b[A\n",
      " 47%|████▋     | 47/100 [00:04<00:05, 10.08it/s]\u001b[A\n",
      " 49%|████▉     | 49/100 [00:04<00:05, 10.12it/s]\u001b[A\n",
      " 51%|█████     | 51/100 [00:05<00:04, 10.06it/s]\u001b[A\n",
      " 53%|█████▎    | 53/100 [00:05<00:04, 10.07it/s]\u001b[A\n",
      " 55%|█████▌    | 55/100 [00:05<00:04,  9.97it/s]\u001b[A\n",
      " 56%|█████▌    | 56/100 [00:05<00:04,  9.91it/s]\u001b[A\n",
      " 57%|█████▋    | 57/100 [00:05<00:04,  9.84it/s]\u001b[A\n",
      " 58%|█████▊    | 58/100 [00:05<00:04,  9.84it/s]\u001b[A\n",
      " 59%|█████▉    | 59/100 [00:06<00:04,  9.72it/s]\u001b[A\n",
      " 60%|██████    | 60/100 [00:06<00:04,  9.62it/s]\u001b[A\n",
      " 61%|██████    | 61/100 [00:06<00:04,  9.36it/s]\u001b[A\n",
      " 62%|██████▏   | 62/100 [00:06<00:03,  9.52it/s]\u001b[A\n",
      " 63%|██████▎   | 63/100 [00:06<00:03,  9.52it/s]\u001b[A\n",
      " 64%|██████▍   | 64/100 [00:06<00:03,  9.61it/s]\u001b[A\n",
      " 65%|██████▌   | 65/100 [00:06<00:03,  9.56it/s]\u001b[A\n",
      " 66%|██████▌   | 66/100 [00:06<00:03,  9.67it/s]\u001b[A\n",
      " 67%|██████▋   | 67/100 [00:06<00:03,  9.60it/s]\u001b[A\n",
      " 68%|██████▊   | 68/100 [00:06<00:03,  9.62it/s]\u001b[A\n",
      " 69%|██████▉   | 69/100 [00:07<00:03,  9.61it/s]\u001b[A\n",
      " 70%|███████   | 70/100 [00:07<00:03,  9.71it/s]\u001b[A\n",
      " 71%|███████   | 71/100 [00:07<00:02,  9.72it/s]\u001b[A\n",
      " 72%|███████▏  | 72/100 [00:07<00:02,  9.76it/s]\u001b[A\n",
      " 73%|███████▎  | 73/100 [00:07<00:02,  9.62it/s]\u001b[A\n",
      " 74%|███████▍  | 74/100 [00:07<00:02,  9.65it/s]\u001b[A\n",
      " 75%|███████▌  | 75/100 [00:07<00:02,  9.50it/s]\u001b[A\n",
      " 76%|███████▌  | 76/100 [00:07<00:02,  9.57it/s]\u001b[A\n",
      " 77%|███████▋  | 77/100 [00:07<00:02,  9.63it/s]\u001b[A\n",
      " 78%|███████▊  | 78/100 [00:07<00:02,  9.73it/s]\u001b[A\n",
      " 79%|███████▉  | 79/100 [00:08<00:02,  9.68it/s]\u001b[A\n",
      " 80%|████████  | 80/100 [00:08<00:02,  9.64it/s]\u001b[A\n",
      " 81%|████████  | 81/100 [00:08<00:01,  9.57it/s]\u001b[A\n",
      " 82%|████████▏ | 82/100 [00:08<00:01,  9.58it/s]\u001b[A\n",
      " 83%|████████▎ | 83/100 [00:08<00:01,  9.62it/s]\u001b[A\n",
      " 84%|████████▍ | 84/100 [00:08<00:01,  9.63it/s]\u001b[A\n",
      " 85%|████████▌ | 85/100 [00:08<00:01,  9.63it/s]\u001b[A\n",
      " 86%|████████▌ | 86/100 [00:08<00:01,  9.46it/s]\u001b[A\n",
      " 87%|████████▋ | 87/100 [00:08<00:01,  9.44it/s]\u001b[A\n",
      " 88%|████████▊ | 88/100 [00:09<00:01,  9.35it/s]\u001b[A\n",
      " 89%|████████▉ | 89/100 [00:09<00:01,  9.36it/s]\u001b[A\n",
      " 90%|█████████ | 90/100 [00:09<00:01,  9.36it/s]\u001b[A\n",
      " 91%|█████████ | 91/100 [00:09<00:00,  9.46it/s]\u001b[A\n",
      " 92%|█████████▏| 92/100 [00:09<00:00,  9.52it/s]\u001b[A\n",
      " 94%|█████████▍| 94/100 [00:09<00:00,  9.75it/s]\u001b[A\n",
      " 95%|█████████▌| 95/100 [00:09<00:00,  9.60it/s]\u001b[A\n",
      " 96%|█████████▌| 96/100 [00:09<00:00,  9.56it/s]\u001b[A\n",
      " 97%|█████████▋| 97/100 [00:09<00:00,  9.66it/s]\u001b[A\n",
      " 98%|█████████▊| 98/100 [00:10<00:00,  9.58it/s]\u001b[A\n",
      " 99%|█████████▉| 99/100 [00:10<00:00,  9.61it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.67it/s]\u001b[A\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:00<00:17,  5.80it/s]\u001b[A\n",
      "  2%|▏         | 2/100 [00:00<00:15,  6.49it/s]\u001b[A\n",
      "  3%|▎         | 3/100 [00:00<00:13,  7.25it/s]\u001b[A\n",
      "  4%|▍         | 4/100 [00:00<00:12,  7.84it/s]\u001b[A\n",
      "  5%|▌         | 5/100 [00:00<00:11,  8.28it/s]\u001b[A\n",
      "  6%|▌         | 6/100 [00:00<00:10,  8.59it/s]\u001b[A\n",
      "  7%|▋         | 7/100 [00:00<00:10,  8.78it/s]\u001b[A\n",
      "  8%|▊         | 8/100 [00:00<00:10,  9.09it/s]\u001b[A\n",
      "  9%|▉         | 9/100 [00:01<00:09,  9.25it/s]\u001b[A\n",
      " 10%|█         | 10/100 [00:01<00:09,  9.28it/s]\u001b[A\n",
      " 11%|█         | 11/100 [00:01<00:09,  9.46it/s]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:01<00:09,  9.29it/s]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:01<00:09,  8.85it/s]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:01<00:09,  9.03it/s]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:01<00:09,  9.27it/s]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:01<00:09,  9.27it/s]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:01<00:08,  9.32it/s]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:01<00:08,  9.39it/s]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:02<00:08,  9.37it/s]\u001b[A\n",
      " 20%|██        | 20/100 [00:02<00:08,  9.50it/s]\u001b[A\n",
      " 21%|██        | 21/100 [00:02<00:08,  9.59it/s]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:02<00:08,  9.51it/s]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:02<00:07,  9.76it/s]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:02<00:07,  9.66it/s]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:02<00:07,  9.52it/s]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:02<00:07,  9.59it/s]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:03<00:07,  9.59it/s]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:03<00:07,  9.40it/s]\u001b[A\n",
      " 30%|███       | 30/100 [00:03<00:07,  9.40it/s]\u001b[A\n",
      " 31%|███       | 31/100 [00:03<00:07,  9.36it/s]\u001b[A\n",
      " 32%|███▏      | 32/100 [00:03<00:07,  9.33it/s]\u001b[A\n",
      " 33%|███▎      | 33/100 [00:03<00:07,  9.27it/s]\u001b[A\n",
      " 34%|███▍      | 34/100 [00:03<00:07,  9.15it/s]\u001b[A\n",
      " 35%|███▌      | 35/100 [00:03<00:07,  9.22it/s]\u001b[A\n",
      " 36%|███▌      | 36/100 [00:03<00:06,  9.35it/s]\u001b[A\n",
      " 37%|███▋      | 37/100 [00:03<00:06,  9.36it/s]\u001b[A\n",
      " 39%|███▉      | 39/100 [00:04<00:06,  9.61it/s]\u001b[A\n",
      " 40%|████      | 40/100 [00:04<00:06,  9.57it/s]\u001b[A\n",
      " 41%|████      | 41/100 [00:04<00:06,  9.43it/s]\u001b[A\n",
      " 42%|████▏     | 42/100 [00:04<00:06,  9.45it/s]\u001b[A\n",
      " 43%|████▎     | 43/100 [00:04<00:05,  9.55it/s]\u001b[A\n",
      " 44%|████▍     | 44/100 [00:04<00:05,  9.56it/s]\u001b[A\n",
      " 45%|████▌     | 45/100 [00:04<00:05,  9.66it/s]\u001b[A\n",
      " 46%|████▌     | 46/100 [00:04<00:05,  9.24it/s]\u001b[A\n",
      " 47%|████▋     | 47/100 [00:05<00:05,  9.24it/s]\u001b[A\n",
      " 48%|████▊     | 48/100 [00:05<00:05,  9.08it/s]\u001b[A\n",
      " 49%|████▉     | 49/100 [00:05<00:05,  9.34it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:05<00:05,  9.43it/s]\u001b[A\n",
      " 52%|█████▏    | 52/100 [00:05<00:04,  9.66it/s]\u001b[A\n",
      " 53%|█████▎    | 53/100 [00:05<00:04,  9.68it/s]\u001b[A\n",
      " 54%|█████▍    | 54/100 [00:05<00:04,  9.59it/s]\u001b[A\n",
      " 55%|█████▌    | 55/100 [00:05<00:04,  9.21it/s]\u001b[A\n",
      " 56%|█████▌    | 56/100 [00:05<00:04,  9.29it/s]\u001b[A\n",
      " 57%|█████▋    | 57/100 [00:06<00:04,  9.40it/s]\u001b[A\n",
      " 58%|█████▊    | 58/100 [00:06<00:04,  9.36it/s]\u001b[A\n",
      " 59%|█████▉    | 59/100 [00:06<00:04,  9.42it/s]\u001b[A\n",
      " 60%|██████    | 60/100 [00:06<00:04,  9.47it/s]\u001b[A\n",
      " 61%|██████    | 61/100 [00:06<00:04,  9.55it/s]\u001b[A\n",
      " 62%|██████▏   | 62/100 [00:06<00:03,  9.66it/s]\u001b[A\n",
      " 63%|██████▎   | 63/100 [00:06<00:03,  9.75it/s]\u001b[A\n",
      " 64%|██████▍   | 64/100 [00:06<00:03,  9.78it/s]\u001b[A\n",
      " 65%|██████▌   | 65/100 [00:06<00:03,  9.70it/s]\u001b[A\n",
      " 66%|██████▌   | 66/100 [00:07<00:03,  9.43it/s]\u001b[A\n",
      " 67%|██████▋   | 67/100 [00:07<00:03,  9.57it/s]\u001b[A\n",
      " 68%|██████▊   | 68/100 [00:07<00:03,  9.58it/s]\u001b[A\n",
      " 69%|██████▉   | 69/100 [00:07<00:03,  9.09it/s]\u001b[A\n",
      " 70%|███████   | 70/100 [00:07<00:03,  9.30it/s]\u001b[A\n",
      " 71%|███████   | 71/100 [00:07<00:03,  9.27it/s]\u001b[A\n",
      " 72%|███████▏  | 72/100 [00:07<00:03,  9.26it/s]\u001b[A\n",
      " 73%|███████▎  | 73/100 [00:07<00:02,  9.23it/s]\u001b[A\n",
      " 74%|███████▍  | 74/100 [00:07<00:02,  9.27it/s]\u001b[A\n",
      " 75%|███████▌  | 75/100 [00:07<00:02,  9.33it/s]\u001b[A\n",
      " 76%|███████▌  | 76/100 [00:08<00:02,  9.22it/s]\u001b[A\n",
      " 77%|███████▋  | 77/100 [00:08<00:02,  9.42it/s]\u001b[A\n",
      " 78%|███████▊  | 78/100 [00:08<00:02,  9.53it/s]\u001b[A\n",
      " 79%|███████▉  | 79/100 [00:08<00:02,  9.42it/s]\u001b[A\n",
      " 80%|████████  | 80/100 [00:08<00:02,  9.50it/s]\u001b[A\n",
      " 81%|████████  | 81/100 [00:08<00:02,  9.49it/s]\u001b[A\n",
      " 82%|████████▏ | 82/100 [00:08<00:01,  9.36it/s]\u001b[A\n",
      " 83%|████████▎ | 83/100 [00:08<00:01,  9.44it/s]\u001b[A\n",
      " 84%|████████▍ | 84/100 [00:08<00:01,  9.52it/s]\u001b[A\n",
      " 85%|████████▌ | 85/100 [00:09<00:01,  9.43it/s]\u001b[A\n",
      " 86%|████████▌ | 86/100 [00:09<00:01,  9.47it/s]\u001b[A\n",
      " 87%|████████▋ | 87/100 [00:09<00:01,  9.22it/s]\u001b[A\n",
      " 88%|████████▊ | 88/100 [00:09<00:01,  9.24it/s]\u001b[A\n",
      " 89%|████████▉ | 89/100 [00:09<00:01,  9.33it/s]\u001b[A\n",
      " 90%|█████████ | 90/100 [00:09<00:01,  9.47it/s]\u001b[A\n",
      " 91%|█████████ | 91/100 [00:09<00:00,  9.23it/s]\u001b[A\n",
      " 92%|█████████▏| 92/100 [00:09<00:00,  9.39it/s]\u001b[A\n",
      " 93%|█████████▎| 93/100 [00:09<00:00,  9.50it/s]\u001b[A\n",
      " 94%|█████████▍| 94/100 [00:10<00:00,  9.39it/s]\u001b[A\n",
      " 95%|█████████▌| 95/100 [00:10<00:00,  9.36it/s]\u001b[A\n",
      " 96%|█████████▌| 96/100 [00:10<00:00,  9.34it/s]\u001b[A\n",
      " 97%|█████████▋| 97/100 [00:10<00:00,  9.37it/s]\u001b[A\n",
      " 98%|█████████▊| 98/100 [00:10<00:00,  9.32it/s]\u001b[A\n",
      " 99%|█████████▉| 99/100 [00:10<00:00,  9.22it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.27it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final test losses\n",
      "nonprivate: 0.09, private: 26.80\n",
      "final test accs\n",
      "nonprivate: 98.00, private: 26.00\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "EPSILON = 2.\n",
    "LMBDA = 5e-4\n",
    "EPOCHS = 100  # run for more epochs once your code works\n",
    "BATCH_SIZE = 256\n",
    "LR = .1\n",
    "DATA_SEED = 0\n",
    "MODEL_SEED = 0\n",
    "main(N, EPSILON, LMBDA, EPOCHS, BATCH_SIZE, LR, DATA_SEED, MODEL_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answers\n",
    "\n",
    "True or False\n",
    "\n",
    "1- False\n",
    "\n",
    "2- False\n",
    "\n",
    "3- False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
