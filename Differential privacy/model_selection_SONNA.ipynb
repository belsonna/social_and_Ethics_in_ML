{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Private Model Selection.\"\"\"\n",
    "import argparse\n",
    "from glob import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from utils import get_data_loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_probs(ndarray_of_probs, name):\n",
    "    if not isinstance(ndarray_of_probs, np.ndarray):\n",
    "        msg = 'ndarray_of_probs should be a np.ndarray. ' + \\\n",
    "                'Make sure to convert from torch.tensor if need be.'\n",
    "        raise ValueError(msg)\n",
    "    if not isinstance(name, str):\n",
    "        raise ValueError('name should be a str')\n",
    "\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    dirname = './figs'\n",
    "    filename = os.path.join(dirname, name) + '.model-selection-probs.png'\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    fig, ax = plt.subplots()\n",
    "    model_idxs = np.arange(len(ndarray_of_probs))\n",
    "    ax.bar(model_idxs, ndarray_of_probs)\n",
    "    ax.set_xlabel('model idx')\n",
    "    ax.set_ylabel('prob of being selected under Exp Mech')\n",
    "    ax.set_title(name)\n",
    "    ax.set_xticks(model_idxs)\n",
    "    fig.savefig(filename)\n",
    "    return filename\n",
    "\n",
    "\n",
    "def load_models(num_pixels):\n",
    "    \"\"\"Randomly samples k pre-trained models parameters (from the list of ten)\n",
    "    \"\"\"\n",
    "    list_of_model_filenames = glob('./pretrained_models/*.pt')\n",
    "    list_of_model_filenames.sort()\n",
    "    list_of_models = []\n",
    "    for model_filename in list_of_model_filenames:\n",
    "        model = nn.Linear(num_pixels, 1, bias=False)\n",
    "        model.load_state_dict(torch.load(model_filename))\n",
    "        list_of_models.append(model)\n",
    "    return list_of_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import logsumexp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_scores(list_of_models, test_loader):\n",
    "    \"\"\"Compute score (performance on private test data) for each model\"\"\"\n",
    "    if not isinstance(list_of_models, list):\n",
    "        raise ValueError('first argument should be a list')\n",
    "    if not isinstance(test_loader, DataLoader):\n",
    "        raise ValueError('second argument should be pytorch data loader')\n",
    "    ############################################################################\n",
    "    # TODO(student)\n",
    "    #\n",
    "    # your code here...\n",
    "    #\n",
    "    # You can look into logistic_regression.py to see how various training \n",
    "    # metrics are computed given the model\n",
    "    #\n",
    "    n= len(list_of_models)\n",
    "    total= len(test_loader.dataset) \n",
    "    scores=np.zeros(n)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    for i in range(n):\n",
    "        model= list_of_models[i]\n",
    "        losses= 0\n",
    "        #loss=0\n",
    "        for j,(images, labels) in enumerate(test_loader):\n",
    "            images = images.reshape(-1, 28*28)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "            losses += loss * (len(images) / float(total))\n",
    "        scores[i]=1.0-losses\n",
    "    return torch.Tensor(scores) \n",
    "    ############################################################################\n",
    "    \n",
    "    \n",
    "def exponential_mechanism(list_of_models, test_loader, epsilon):\n",
    "    \"\"\"Sample from model list, where sampling probability scales with test score\n",
    "    \n",
    "    Return both the sampled model and the sample index\n",
    "    \"\"\"\n",
    "    if not isinstance(list_of_models, list):\n",
    "        raise ValueError('first argument should be a list')\n",
    "    if not isinstance(test_loader, DataLoader):\n",
    "        raise ValueError('second argument should be pytorch data loader')\n",
    "\n",
    "    scores = compute_scores(list_of_models, test_loader)\n",
    "    num_test_examples = len(test_loader.dataset)\n",
    "    n= scores.shape[0]\n",
    "\n",
    "    ############################################################################\n",
    "    # TODO(student)\n",
    "    #\n",
    "    # your code here...\n",
    "    #\n",
    "    # hint: you're exponential mechanism should somehow depend on the number of\n",
    "    # training data in test loader\n",
    "    \n",
    "    #\n",
    "    probs= scores * epsilon\n",
    "    som= logsumexp(probs)\n",
    "\n",
    "    sample_probs = np.array(np.exp(probs - som))\n",
    "    prob= np.random.choice(sample_probs)\n",
    "    \n",
    "    sampled_idx,= np.where(sample_probs == prob)\n",
    "    #print(sampled_idx)\n",
    "    sampled_model= list_of_models[sampled_idx[0]]\n",
    "    ############################################################################\n",
    "    return sampled_model, sampled_idx, sample_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 250\n",
    "SEED = 3771\n",
    "\n",
    "def main(n, epsilon):\n",
    "    loaders, _ = get_data_loaders(SEED, BATCH_SIZE, \n",
    "            num_train=13006, num_test=n)\n",
    "    num_pixels = loaders['train'].dataset.num_pixels\n",
    "    models = load_models(num_pixels)\n",
    "\n",
    "    private_best_model, private_best_model_idx, sample_probs \\\n",
    "            = exponential_mechanism(models, loaders['test'], epsilon)\n",
    "\n",
    "    print('selected model', private_best_model_idx)\n",
    "    #print('selected model:', private_best_model)\n",
    "    name = 'eps={},n={}'.format(epsilon, n)\n",
    "    filename = plot_probs(sample_probs, name)\n",
    "    print('see plot at', filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arguments and main function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected model [8]\n",
      "see plot at ./figs/eps=1.0,n=10.model-selection-probs.png\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "EPSILON = 1.\n",
    "main(N, EPSILON)\n",
    "# TODO(student): sweep over the required values for N and EPSILON and produce \n",
    "#                several plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected model [8]\n",
      "see plot at ./figs/eps=1,n=2.model-selection-probs.png\n",
      "selected model [0]\n",
      "see plot at ./figs/eps=1,n=10.model-selection-probs.png\n",
      "selected model [6]\n",
      "see plot at ./figs/eps=1,n=100.model-selection-probs.png\n",
      "selected model [0]\n",
      "see plot at ./figs/eps=1,n=1000.model-selection-probs.png\n",
      "selected model [2]\n",
      "see plot at ./figs/eps=2,n=2.model-selection-probs.png\n",
      "selected model [6]\n",
      "see plot at ./figs/eps=2,n=10.model-selection-probs.png\n",
      "selected model [1]\n",
      "see plot at ./figs/eps=2,n=100.model-selection-probs.png\n",
      "selected model [7]\n",
      "see plot at ./figs/eps=2,n=1000.model-selection-probs.png\n",
      "selected model [1]\n",
      "see plot at ./figs/eps=4,n=2.model-selection-probs.png\n",
      "selected model [5]\n",
      "see plot at ./figs/eps=4,n=10.model-selection-probs.png\n",
      "selected model [5]\n",
      "see plot at ./figs/eps=4,n=100.model-selection-probs.png\n",
      "selected model [9]\n",
      "see plot at ./figs/eps=4,n=1000.model-selection-probs.png\n"
     ]
    }
   ],
   "source": [
    "# testons les valeurs\n",
    "\n",
    "epsilons=[1,2,4]\n",
    "sizes=[2,10,100,1000]\n",
    "\n",
    "for epsilon in epsilons:\n",
    "    for n in sizes:\n",
    "        main(n,epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers\n",
    "\n",
    "\n",
    "\n",
    "The aim of this section is to answer the question ”What model classifier yield a good result on the test data?”. \n",
    "From the plots above, the answer is not far-fetched. The test data private and using exponential mechanism, we observe\n",
    "that despite the varying values for epsilon , the model idx 5 and 8 achieve high probability even with the changes in the number of test data. I do not see how increase in the test data could affect the probability because its considered\n",
    "private in the first case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
